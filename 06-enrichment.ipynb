{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we compute and aggregate statistics for the enrichment of conditions in cases versus controls, as well as in each cluster versus all the other clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by defining a generic function to compute enrichment given \"cases\" and \"controls\" AnnDatas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "# generic function to compoute enrichment\n",
    "def enrichment(cases, controls, save_path):\n",
    "    \n",
    "    # pull out conditions to iterate through\n",
    "    conditions = cases.var[\"<concept ID>\"].tolist()\n",
    "    assert conditions == controls.var[\"<concept ID>\"].tolist(), \"Columns must match between cases and controls.\"\n",
    "    n_conditions = len(conditions)\n",
    "    \n",
    "    # convert to column-based matrices for faster operations\n",
    "    print(\"converting to CSC format...\")\n",
    "    cases_mat = cases.X.tocsc()\n",
    "    controls_mat = controls.X.tocsc()\n",
    "    \n",
    "    # create dictionary to look up condition names\n",
    "    condition_dict = cases.var.set_index(\"<concept ID>\")[\"<concept name>\"].to_dict()\n",
    "    \n",
    "    # iterate over conditions\n",
    "    print(\"iterating over conditions...\")\n",
    "    results = []\n",
    "    for i, c in enumerate(tqdm(conditions)):\n",
    "        \n",
    "        # create contingency table\n",
    "        cases_with = cases_mat[:, i].sum()\n",
    "        controls_with = controls_mat[:, i].sum()\n",
    "        obs = np.array([\n",
    "            [cases_with, controls_with],\n",
    "            [cases_mat.shape[0] - cases_with, controls_mat.shape[0] - controls_with]\n",
    "        ])\n",
    "        \n",
    "        # zero-count correction if needed\n",
    "        if (obs == 0).any():\n",
    "            obs += 1\n",
    "\n",
    "        # compute odds ratio and bounds\n",
    "        odds = (obs[0, 0] * obs[1, 1]) / (obs[0, 1] * obs[1, 0])\n",
    "        width = 1.96 * np.sqrt((1 / obs[0, 0]) + (1 / obs[0, 1]) + (1 / obs[1, 0]) + (1 / obs[1, 1]))\n",
    "        lower = np.exp(np.log(odds) - width)\n",
    "        upper = np.exp(np.log(odds) + width)\n",
    "        \n",
    "        # set up hypergeometric distribution parameters\n",
    "        # M: size of population\n",
    "        # n: number of successes in population\n",
    "        # N: size of selection\n",
    "        # x: number of successes in selection\n",
    "        M = cases.shape[0] + controls.shape[0]\n",
    "        n = obs[0, 0] + obs[0, 1]\n",
    "        if odds >= 1:\n",
    "            N = cases.shape[0]\n",
    "            x = obs[0, 0]\n",
    "        else:\n",
    "            N = controls.shape[0]\n",
    "            x = obs[0, 1]\n",
    "            \n",
    "        # compute p-value and apply Bonferroni correction\n",
    "        p = hypergeom(M=M, n=n, N=N).sf(x - 1)\n",
    "        p_adj = p * n_conditions\n",
    "        \n",
    "        # record result\n",
    "        results.append({\n",
    "            \"snomed\": c,\n",
    "            \"name\": condition_dict[c],\n",
    "            \"odds\": odds,\n",
    "            \"lower\": lower,\n",
    "            \"upper\": upper,\n",
    "            \"p\": p,\n",
    "            \"p-adj\": p_adj,\n",
    "            \"sig\": p_adj < 0.05,\n",
    "            \"cases_with\": int(cases_with),\n",
    "            \"controls_with\": int(controls_with),\n",
    "            \"cases_without\": int(obs[1, 0]),\n",
    "            \"controls_without\": int(obs[1, 1])\n",
    "        })\n",
    "        \n",
    "    # convert to DataFrame and save\n",
    "    print(\"saving results...\")\n",
    "    results = pd.DataFrame.from_records(results).sort_values([\"p-adj\", \"odds\"], ascending=[True, False]).reset_index(drop=True)\n",
    "    results.to_csv(save_path, index=False)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by comparing all conditions across cases versus controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load full AnnData, remove endometriosis concepts\n",
    "endo_concepts = pd.read_csv(\"<concept filepath>\")[\"<concept ID>\"].tolist()\n",
    "adata = sc.read_h5ad(\"<AnnData filepath for all patients, all conditions>\")\n",
    "adata = adata[:, ~adata.var[\"<concept ID>\"].isin(endo_concepts)]\n",
    "\n",
    "# iterate over match replicates\n",
    "for i in range(1, 31):\n",
    "    \n",
    "    # print progress\n",
    "    print(f\"\\n===== replicate {i} of 30 =====\\n\")\n",
    "    \n",
    "    # subset to replicate and filter conditions\n",
    "    print(\"subsetting AnnData and filtering conditions...\")\n",
    "    subad = adata[adata.obs[\"replicate\"].isin((0, i))]\n",
    "    sc.pp.filter_genes(subad, min_counts=1)\n",
    "    \n",
    "    # split cases and controls and run enrichment analysis\n",
    "    cases = subad[subad.obs[\"endo\"] == 1]\n",
    "    controls = subad[subad.obs[\"endo\"] == 0]\n",
    "    _ = enrichment(cases, controls, f\"<directory for full case versus control analysis>/replicate-{i:02}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compare pre-endometriosis conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load AnnData\n",
    "adata = sc.read_h5ad(\"<AnnData filepath for all patients, pre-endo conditions>\")\n",
    "\n",
    "# iterate over match replicates\n",
    "for i in range(1, 31):\n",
    "    \n",
    "    # print progress\n",
    "    print(f\"\\n===== replicate {i} of 30 =====\\n\")\n",
    "    \n",
    "    # subset to replicate and filter conditions\n",
    "    print(\"subsetting AnnData and filtering conditions...\")\n",
    "    subad = adata[adata.obs[\"replicate\"].isin((0, i))]\n",
    "    sc.pp.filter_genes(subad, min_counts=1)\n",
    "    \n",
    "    # split cases and controls and run enrichment analysis\n",
    "    cases = subad[subad.obs[\"endo\"] == 1]\n",
    "    controls = subad[subad.obs[\"endo\"] == 0]\n",
    "    _ = enrichment(cases, controls, f\"<directory for pre-endo case versus control analysis>/replicate-{i:02}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute aggregate statistics across the replicates for the case versus control analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agg_results(directory, save_path):\n",
    "    \n",
    "    # load all results into a single DataFrame\n",
    "    all_results = None\n",
    "    for i in range(1, 31):\n",
    "        df = pd.read_csv(f\"{directory}/replicate-{i:02}.csv\")\n",
    "        df[\"replicate\"] = [i] * df.shape[0]\n",
    "        if all_results is None:\n",
    "            all_results = df\n",
    "        else:\n",
    "            all_results = pd.concat([all_results, df], ignore_index=True)\n",
    "    \n",
    "    # get all conditions\n",
    "    all_conditions = sorted(all_results[\"snomed\"].unique().tolist())\n",
    "\n",
    "    # get aggregate metrics for each conditions\n",
    "    records = []\n",
    "    for c in tqdm(all_conditions):\n",
    "        df = all_results[all_results[\"snomed\"] == c]\n",
    "        agg_p_adj = df[\"p-adj\"].mean() * 2\n",
    "        records.append({\n",
    "            \"snomed\": c,\n",
    "            \"name\": df[\"name\"].unique().item(),\n",
    "            \"avg-odds\": df[\"odds\"].mean(),\n",
    "            \"agg-p-adj\": agg_p_adj,\n",
    "            \"agg-sig\": agg_p_adj < 0.05,\n",
    "            \"sig-frac\": df[\"sig\"].mean(),\n",
    "            \"avg-cases-with\": df[\"cases_with\"].mean(),\n",
    "            \"avg-controls-with\": df[\"controls_with\"].mean(),\n",
    "            \"avg-cases-without\": df[\"cases_without\"].mean(),\n",
    "            \"avg-controls-without\": df[\"controls_without\"].mean()\n",
    "        })\n",
    "        \n",
    "    # convert to DataFrame, save and return\n",
    "    agg_results = pd.DataFrame.from_records(records).sort_values([\"agg-p-adj\", \"avg-odds\"], ascending=[True, False]).reset_index(drop=True)\n",
    "    agg_results.to_csv(save_path, index=False)\n",
    "    return agg_results\n",
    "\n",
    "# run for case versus control analyses\n",
    "agg_results(\"<directory for full case versus control analysis>\", \"<full case versus control results filepath>\")\n",
    "agg_results(\"<directory for pre-endo case versus control analysis>\", \"<pre-endo case versus control results filepath>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the clusters, we use the same functions but select different \"case\" and \"control\" groups based on the cluster under consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis for clusters using all conditions\n",
    "full_results = {}\n",
    "adata = sc.read_h5ad(\"<AnnData filepath for endo patients, all conditions>\")\n",
    "adata = adata[:, ~adata.var[\"<concept ID>\"].isin(endo_concepts)]\n",
    "clusters = sorted(adata.obs[\"leiden\"].unique().tolist())\n",
    "for cluster in clusters:\n",
    "    print(f\"\\n===== cluster {cluster} of {len(clusters)} =====\\n\")\n",
    "    cluster_str = f\"{int(cluster):02}\"\n",
    "    cases = adata[adata.obs[\"leiden\"] == cluster]\n",
    "    controls = adata[adata.obs[\"leiden\"] != cluster]\n",
    "    full_results[cluster_str] = enrichment(cases, controls, f\"<directory for cluster analysis, all conditions>/cluster-{cluster_str}.csv\")\n",
    "\n",
    "# analysis for clusters using pre-endometriosis conditions\n",
    "pre_results = {}\n",
    "adata = sc.read_h5ad(\"<AnnData filepath for endo patients, pre-endo conditions>\")\n",
    "adata = adata[:, ~adata.var[\"<concept ID>\"].isin(endo_concepts)]\n",
    "clusters = sorted(adata.obs[\"leiden\"].unique().tolist())\n",
    "for cluster in clusters:\n",
    "    print(f\"\\n===== cluster {cluster} of {len(clusters)} =====\\n\")\n",
    "    cluster_str = f\"{int(cluster):02}\"\n",
    "    cases = adata[adata.obs[\"leiden\"] == cluster]\n",
    "    controls = adata[adata.obs[\"leiden\"] != cluster]\n",
    "    pre_results[cluster_str] = enrichment(cases, controls, f\"<directory for cluster analysis, pre-endo conditions>/cluster-{cluster_str}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cluster, we want to keep only the conditions that were exclusively significantly enriched in that cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a list of paths and make a version of each result with only exclusively enriched conditions\n",
    "def make_unique(paths):\n",
    "    \n",
    "    # load in significant conditions for each path\n",
    "    print(\"loading significant enrichments...\")\n",
    "    enrichments = {}\n",
    "    for p in tqdm(paths):\n",
    "        enrichments[p] = pd.read_csv(p)\n",
    "        enrichments[p] = enrichments[p][enrichments[p][\"sig\"] == True]\n",
    "        \n",
    "    # keep only unique conditions\n",
    "    print(\"finding unique conditions...\")\n",
    "    for p in tqdm(paths):\n",
    "\n",
    "        # get initial set of conditions\n",
    "        this_conditions = set(enrichments[p][\"snomed\"])\n",
    "\n",
    "        # get set of all conditions from other clusters\n",
    "        other_paths = paths.copy()\n",
    "        other_paths.remove(p)\n",
    "        other_conditions = set()\n",
    "        for i in other_paths:\n",
    "            other_conditions |= set(enrichments[i][\"snomed\"])\n",
    "\n",
    "        # set difference to get conditions to keep\n",
    "        keep_conditions = this_conditions - other_conditions\n",
    "\n",
    "        # only keep those conditions\n",
    "        enrichments[p] = enrichments[p][enrichments[p][\"snomed\"].isin(keep_conditions)]\n",
    "        enrichments[p] = enrichments[p].sort_values([\"p\", \"odds\"], ascending=[True, False]).reset_index(drop=True)\n",
    "        \n",
    "    # write results to disk\n",
    "    print(\"saving results...\")\n",
    "    for p in tqdm(paths):\n",
    "        enrichments[p].to_csv(p[:-14] + \"unique-\" + p[-14:], index=False)\n",
    "\n",
    "# run for cluster analyses\n",
    "make_unique(sorted(glob(\"<directory for cluster analysis, all conditions>/cluster-*\")))\n",
    "make_unique(sorted(glob(\"<directory for cluster analysis, pre-endo conditions>/cluster-*\")))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
